{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Neural Network trained on CIFAR10 Data\n",
        "\n",
        "Author: Brady Gho\n",
        "\n",
        "Created on 7/15/2024, last editted on 7/15/2024"
      ],
      "metadata": {
        "id": "0KLS-45LjKgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Meta Parameters\n",
        "\n",
        "LEARNING_RATE = 0.03\n",
        "EPOCHS=50\n",
        "BATCH_SIZE=64\n",
        "LAMBDA=0.0001"
      ],
      "metadata": {
        "id": "mf654GY7NmXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Data\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # add more transformations here\n",
        "])\n",
        "\n",
        "traindata = torchvision.datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_set= torchvision.datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "val_size = int(len(traindata)*0.2)\n",
        "train_size = int(len(traindata)*0.8)\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(traindata, [train_size, val_size])\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_set, batch_size = BATCH_SIZE, shuffle=False)\n",
        "test_dataloader = DataLoader(test_set, batch_size = BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc0luJRUncVn",
        "outputId": "04fec2d6-19dd-4c8d-ab0c-748b73cd6813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILP7-RrHUbN6"
      },
      "outputs": [],
      "source": [
        "# Defining the Network\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BradyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BradyCNN, self).__init__()\n",
        "    # cl = convolutional layer, fc = fully connected layer\n",
        "    self.cl1 = nn.Conv2d(3, 8, kernel_size=5, stride=1, padding=2)\n",
        "    self.cl2 = nn.Conv2d(8, 15, kernel_size=5, stride=1)\n",
        "    self.cl3 = nn.Conv2d(15, 27, kernel_size=3, stride=1)\n",
        "    # Add conv layers\n",
        "    # Change kernel size\n",
        "    # mess around with dimension\n",
        "\n",
        "    self.fc1 = nn.Linear(27*4*4, 280)\n",
        "    self.fc2 = nn.Linear(280, 49)\n",
        "    self.fc3 = nn.Linear(49, 10)\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "    self.ReLU = nn.ReLU()\n",
        "    self.maxPool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "    # kernel size = 3, stride = 2\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.ReLU(self.cl1(x))  # 32 x 32\n",
        "      x = self.maxPool(x)         # 16 x 16\n",
        "      x = self.ReLU(self.cl2(x))  # 12 x 12\n",
        "      x = self.ReLU(self.cl3(x))  # 10x10\n",
        "      x = self.maxPool(x)         # 5 x 5\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = self.ReLU(self.fc1(x))\n",
        "      x = self.dropout(x)\n",
        "      x = self.ReLU(self.fc2(x))\n",
        "      x = self.dropout(x)\n",
        "      x = self.softmax(self.fc3(x))\n",
        "      return x\n",
        "\n",
        "def eval_model(model, dataloader, criterion):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, answers in dataloader:\n",
        "      predictions = model(inputs)\n",
        "      loss = criterion(predictions, answers)\n",
        "      total_loss += loss.sum()\n",
        "\n",
        "      predictions = torch.argmax(predictions, dim=1)\n",
        "      correct = (predictions == answers).float().sum()\n",
        "      total_correct+=correct\n",
        "\n",
        "  return total_loss / len(dataloader), round(100 * float(total_correct / (len(dataloader)*BATCH_SIZE)), 4)\n",
        "\n",
        "def loss_function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN = BradyCNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "val_accuracy_history = []\n",
        "\n",
        "initial_test_loss, initial_test_accuracy = eval_model(CNN, test_dataloader, criterion)"
      ],
      "metadata": {
        "id": "Nf7EKV_hOhq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "\n",
        "import torch.optim as optim\n",
        "import numpy\n",
        "\n",
        "optimizer = optim.Adagrad(CNN.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  CNN.train()\n",
        "  for inputs, answers in train_dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    predictions = CNN(inputs)\n",
        "    loss = criterion(predictions, answers)\n",
        "\n",
        "    L2_reg = 0\n",
        "    for param in CNN.parameters():\n",
        "      L2_reg += torch.sum(torch.square(param))\n",
        "    loss+=LAMBDA*L2_reg\n",
        "\n",
        "    train_loss_history.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  eval_loss, eval_accuracy = eval_model(CNN, val_dataloader, criterion)\n",
        "  print(f\"Epoch {epoch+1}: Loss = {eval_loss}, Accuracy = {eval_accuracy}%\")\n",
        "\n",
        "  val_loss_history.append(eval_loss)\n",
        "  val_accuracy_history.append(eval_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "vAcKi1xusWsm",
        "outputId": "b726c95e-fe16-4713-fe3c-29727c01292a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 2.302597999572754, Accuracy = 9.7333%\n",
            "Epoch 2: Loss = 2.223776340484619, Accuracy = 20.5414%\n",
            "Epoch 3: Loss = 2.1835389137268066, Accuracy = 26.2838%\n",
            "Epoch 4: Loss = 2.1670663356781006, Accuracy = 27.9658%\n",
            "Epoch 5: Loss = 2.1701560020446777, Accuracy = 27.1696%\n",
            "Epoch 6: Loss = 2.148444890975952, Accuracy = 29.996%\n",
            "Epoch 7: Loss = 2.1402015686035156, Accuracy = 31.0311%\n",
            "Epoch 8: Loss = 2.132145881652832, Accuracy = 31.6979%\n",
            "Epoch 9: Loss = 2.1329362392425537, Accuracy = 31.5585%\n",
            "Epoch 10: Loss = 2.1210315227508545, Accuracy = 33.1011%\n",
            "Epoch 11: Loss = 2.1202995777130127, Accuracy = 32.8125%\n",
            "Epoch 12: Loss = 2.123422145843506, Accuracy = 32.5637%\n",
            "Epoch 13: Loss = 2.115668535232544, Accuracy = 33.2404%\n",
            "Epoch 14: Loss = 2.110661745071411, Accuracy = 33.8177%\n",
            "Epoch 15: Loss = 2.108877658843994, Accuracy = 34.0864%\n",
            "Epoch 16: Loss = 2.105620861053467, Accuracy = 34.4347%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a5334aa711a6>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_test_loss, final_test_accuracy = eval_model(CNN, test_dataloader, criterion)\n",
        "\n",
        "print(f\"Initial Test Results: Loss = {initial_test_loss}, Accuracy = {initial_test_accuracy}%\")\n",
        "print(f\"Final Test Results: Loss = {final_test_loss}, Accuracy = {final_test_accuracy}%\")"
      ],
      "metadata": {
        "id": "HsOlpN7SOoek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(train_loss_history, label=\"Train Loss History\")\n",
        "plt.title(\"Train Loss History\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(val_loss_history, label=\"Validation Loss History\")\n",
        "plt.title(\"Validation Loss History\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(val_accuracy_history, label=\"Validation Accuracy History\")\n",
        "plt.title(\"Validation Accuracy History\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Percent Accuracy\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-BzrEoXAIK-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}